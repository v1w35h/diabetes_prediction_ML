{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":119082,"databundleVersionId":14993753,"sourceType":"competition"}],"dockerImageVersionId":31234,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-14T20:54:32.823571Z","iopub.execute_input":"2026-01-14T20:54:32.823994Z","iopub.status.idle":"2026-01-14T20:54:34.576569Z","shell.execute_reply.started":"2026-01-14T20:54:32.823963Z","shell.execute_reply":"2026-01-14T20:54:34.575146Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/playground-series-s6e1/sample_submission.csv\n/kaggle/input/playground-series-s6e1/train.csv\n/kaggle/input/playground-series-s6e1/test.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/playground-series-s6e1/train.csv')\ntarget = 'exam_score'\n\ny = train_df[target]\nX = train_df.copy()\n\nX.drop(target,axis=1,inplace=True)\n\nX.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T20:54:37.300230Z","iopub.execute_input":"2026-01-14T20:54:37.300714Z","iopub.status.idle":"2026-01-14T20:54:38.883103Z","shell.execute_reply.started":"2026-01-14T20:54:37.300683Z","shell.execute_reply":"2026-01-14T20:54:38.882150Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"   id  age  gender   course  study_hours  class_attendance internet_access  \\\n0   0   21  female     b.sc         7.91              98.8              no   \n1   1   18   other  diploma         4.95              94.8             yes   \n2   2   20  female     b.sc         4.68              92.6             yes   \n3   3   19    male     b.sc         2.00              49.5             yes   \n4   4   23    male      bca         7.65              86.9             yes   \n\n   sleep_hours sleep_quality   study_method facility_rating exam_difficulty  \n0          4.9       average  online videos             low            easy  \n1          4.7          poor     self-study          medium        moderate  \n2          5.8          poor       coaching            high        moderate  \n3          8.3       average    group study            high        moderate  \n4          9.6          good     self-study            high            easy  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>age</th>\n      <th>gender</th>\n      <th>course</th>\n      <th>study_hours</th>\n      <th>class_attendance</th>\n      <th>internet_access</th>\n      <th>sleep_hours</th>\n      <th>sleep_quality</th>\n      <th>study_method</th>\n      <th>facility_rating</th>\n      <th>exam_difficulty</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>21</td>\n      <td>female</td>\n      <td>b.sc</td>\n      <td>7.91</td>\n      <td>98.8</td>\n      <td>no</td>\n      <td>4.9</td>\n      <td>average</td>\n      <td>online videos</td>\n      <td>low</td>\n      <td>easy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>18</td>\n      <td>other</td>\n      <td>diploma</td>\n      <td>4.95</td>\n      <td>94.8</td>\n      <td>yes</td>\n      <td>4.7</td>\n      <td>poor</td>\n      <td>self-study</td>\n      <td>medium</td>\n      <td>moderate</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>20</td>\n      <td>female</td>\n      <td>b.sc</td>\n      <td>4.68</td>\n      <td>92.6</td>\n      <td>yes</td>\n      <td>5.8</td>\n      <td>poor</td>\n      <td>coaching</td>\n      <td>high</td>\n      <td>moderate</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>19</td>\n      <td>male</td>\n      <td>b.sc</td>\n      <td>2.00</td>\n      <td>49.5</td>\n      <td>yes</td>\n      <td>8.3</td>\n      <td>average</td>\n      <td>group study</td>\n      <td>high</td>\n      <td>moderate</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>23</td>\n      <td>male</td>\n      <td>bca</td>\n      <td>7.65</td>\n      <td>86.9</td>\n      <td>yes</td>\n      <td>9.6</td>\n      <td>good</td>\n      <td>self-study</td>\n      <td>high</td>\n      <td>easy</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X,y, test_size=0.2, random_state=1,stratify=y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T20:54:42.748587Z","iopub.execute_input":"2026-01-14T20:54:42.748982Z","iopub.status.idle":"2026-01-14T20:54:45.684152Z","shell.execute_reply.started":"2026-01-14T20:54:42.748951Z","shell.execute_reply":"2026-01-14T20:54:45.683094Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\n\ndef OneHot(df,ohe):\n    # df = og_df.copy()\n    for col in ohe:\n        dummy1 = pd.get_dummies(df[col],dtype=int,drop_first=True)\n        df = pd.concat([df,dummy1],axis = 1)\n        df.drop(col,axis=1,inplace=True)\n    return df\n\ncols = ['gender','course','internet_access','sleep_quality','study_method','facility_rating','exam_difficulty']\n\nX_train = OneHot(X_train,cols)\nX_val = OneHot(X_val,cols)\n\nss = ['age','study_hours','class_attendance','sleep_hours']\n\nscaler = StandardScaler()\n\nX_train[ss] = scaler.fit_transform(X_train[ss])\nX_val[ss] = scaler.fit_transform(X_val[ss])\n\nX_train.drop('id',axis = 1, inplace=True)\nX_val.drop('id',axis = 1, inplace=True)\n\nX_val.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T20:54:49.712830Z","iopub.execute_input":"2026-01-14T20:54:49.713323Z","iopub.status.idle":"2026-01-14T20:54:51.286268Z","shell.execute_reply.started":"2026-01-14T20:54:49.713291Z","shell.execute_reply":"2026-01-14T20:54:51.285209Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"             age  study_hours  class_attendance  sleep_hours  male  other  \\\n271361  1.082877     1.050546          0.459661     0.817045     0      0   \n370502  1.082877     0.558890          1.273778    -1.419592     0      1   \n519791  1.525420    -0.212501          1.348310     0.243548     0      1   \n372006  1.525420     1.652400          0.213132    -0.960795     0      1   \n251564 -0.687293     0.800480          1.571906     1.046443     0      0   \n\n        b.sc  b.tech  ba  bba  ...  good  poor  group study  mixed  \\\n271361     0       1   0    0  ...     1     0            0      1   \n370502     0       0   1    0  ...     0     1            1      0   \n519791     0       1   0    0  ...     0     1            1      0   \n372006     0       0   0    0  ...     1     0            1      0   \n251564     0       0   0    0  ...     1     0            0      1   \n\n        online videos  self-study  low  medium  hard  moderate  \n271361              0           0    0       0     0         0  \n370502              0           0    0       0     0         0  \n519791              0           0    1       0     0         1  \n372006              0           0    0       0     1         0  \n251564              0           0    0       1     0         1  \n\n[5 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>study_hours</th>\n      <th>class_attendance</th>\n      <th>sleep_hours</th>\n      <th>male</th>\n      <th>other</th>\n      <th>b.sc</th>\n      <th>b.tech</th>\n      <th>ba</th>\n      <th>bba</th>\n      <th>...</th>\n      <th>good</th>\n      <th>poor</th>\n      <th>group study</th>\n      <th>mixed</th>\n      <th>online videos</th>\n      <th>self-study</th>\n      <th>low</th>\n      <th>medium</th>\n      <th>hard</th>\n      <th>moderate</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>271361</th>\n      <td>1.082877</td>\n      <td>1.050546</td>\n      <td>0.459661</td>\n      <td>0.817045</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>370502</th>\n      <td>1.082877</td>\n      <td>0.558890</td>\n      <td>1.273778</td>\n      <td>-1.419592</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>519791</th>\n      <td>1.525420</td>\n      <td>-0.212501</td>\n      <td>1.348310</td>\n      <td>0.243548</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>372006</th>\n      <td>1.525420</td>\n      <td>1.652400</td>\n      <td>0.213132</td>\n      <td>-0.960795</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>251564</th>\n      <td>-0.687293</td>\n      <td>0.800480</td>\n      <td>1.571906</td>\n      <td>1.046443</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 23 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n\nLinReg = LinearRegression()\n\nLinReg.fit(X_train,y_train)\ny_hat_train = LinReg.predict(X_train)\ny_hat_val = LinReg.predict(X_val)\n\nprint(\"     TRAINING SET\")\nprint(f\"R² Score: {r2_score(y_train, y_hat_train):.4f}\")\nprint(f\"Mean Squared Error: {mean_squared_error(y_train, y_hat_train):.4f}\")\nprint(f\"Mean Absolute Error: {mean_absolute_error(y_train, y_hat_train):.4f}\")\nprint(f\"RMSE: {np.sqrt(mean_squared_error(y_train, y_hat_train)):.4f}\")\n\nprint(\"\\n     VALIDATION SET\")\nprint(f\"R² Score: {r2_score(y_val, y_hat_val):.4f}\")\nprint(f\"Mean Squared Error: {mean_squared_error(y_val, y_hat_val):.4f}\")\nprint(f\"Mean Absolute Error: {mean_absolute_error(y_val, y_hat_val):.4f}\")\nprint(f\"RMSE: {np.sqrt(mean_squared_error(y_val, y_hat_val)):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T20:55:17.470713Z","iopub.execute_input":"2026-01-14T20:55:17.471089Z","iopub.status.idle":"2026-01-14T20:55:18.120143Z","shell.execute_reply.started":"2026-01-14T20:55:17.471060Z","shell.execute_reply":"2026-01-14T20:55:18.119232Z"}},"outputs":[{"name":"stdout","text":"     TRAINING SET\nR² Score: 0.7786\nMean Squared Error: 79.2184\nMean Absolute Error: 7.1056\nRMSE: 8.9005\n\n     VALIDATION SET\nR² Score: 0.7801\nMean Squared Error: 78.6844\nMean Absolute Error: 7.0823\nRMSE: 8.8704\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\n# from sklearn.model_selection import GridSearchCV\n\ngb_model = GradientBoostingRegressor(\n    # verbose=1,\n    warm_start=True,\n    n_estimators=1000,\n    max_depth=4,\n    learning_rate=0.1,\n    random_state=1\n)\n\n\n\ngb_model.fit(X_train,y_train)\n\n\ny_hat_train = gb_model.predict(X_train)\ny_hat_val = gb_model.predict(X_val)\n\nprint(\"     TRAINING SET\")\nprint(f\"R² Score: {r2_score(y_train, y_hat_train):.4f}\")\nprint(f\"Mean Squared Error: {mean_squared_error(y_train, y_hat_train):.4f}\")\nprint(f\"Mean Absolute Error: {mean_absolute_error(y_train, y_hat_train):.4f}\")\nprint(f\"RMSE: {np.sqrt(mean_squared_error(y_train, y_hat_train)):.4f}\")\n\nprint(\"\\n     VALIDATION SET\")\nprint(f\"R² Score: {r2_score(y_val, y_hat_val):.4f}\")\nprint(f\"Mean Squared Error: {mean_squared_error(y_val, y_hat_val):.4f}\")\nprint(f\"Mean Absolute Error: {mean_absolute_error(y_val, y_hat_val):.4f}\")\nprint(f\"RMSE: {np.sqrt(mean_squared_error(y_val, y_hat_val)):.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import xgboost as xgb\n\nxg = xgb.XGBRegressor(\n    learning_rate=0.1,\n    max_depth=5,\n    min_child_weight=7,\n    n_estimators=1000,\n    random_state=1,\n    objective='reg:squarederror',\n    eval_metric='rmse'\n)\n\n# cv_params = {\n#     'max_depth': [5, 8, 16], \n#     'min_child_weight': [5, 7, 9], \n#     'n_estimators': [250, 500, 1000]\n# } \n\n# xgb_cv = GridSearchCV(\n#     estimator=xg, \n#     param_grid=cv_params, \n#     scoring='neg_root_mean_squared_error',\n#     cv=5,\n#     refit=True     \n# )\n\n# Optimal parameters: {'max_depth': 5, 'min_child_weight': 7, 'n_estimators': 1000}\n\nxg.fit(X_train,y_train)\n# print(f\"Optimal parameters: {xgb_cv.best_params_}\")\n\ny_hat_train = xg.predict(X_train)\ny_hat_val = xg.predict(X_val)\n\nprint(\"     TRAINING SET\")\nprint(f\"R² Score: {r2_score(y_train, y_hat_train):.4f}\")\nprint(f\"Mean Squared Error: {mean_squared_error(y_train, y_hat_train):.4f}\")\nprint(f\"Mean Absolute Error: {mean_absolute_error(y_train, y_hat_train):.4f}\")\nprint(f\"RMSE: {np.sqrt(mean_squared_error(y_train, y_hat_train)):.4f}\")\n\nprint(\"\\n     VALIDATION SET\")\nprint(f\"R² Score: {r2_score(y_val, y_hat_val):.4f}\")\nprint(f\"Mean Squared Error: {mean_squared_error(y_val, y_hat_val):.4f}\")\nprint(f\"Mean Absolute Error: {mean_absolute_error(y_val, y_hat_val):.4f}\")\nprint(f\"RMSE: {np.sqrt(mean_squared_error(y_val, y_hat_val)):.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-14T19:59:35.326131Z","iopub.execute_input":"2026-01-14T19:59:35.326883Z","iopub.status.idle":"2026-01-14T19:59:59.236557Z","shell.execute_reply.started":"2026-01-14T19:59:35.326779Z","shell.execute_reply":"2026-01-14T19:59:59.235654Z"}},"outputs":[{"name":"stdout","text":"     TRAINING SET\nR² Score: 0.7946\nMean Squared Error: 73.4890\nMean Absolute Error: 6.8353\nRMSE: 8.5726\n\n     VALIDATION SET\nR² Score: 0.7859\nMean Squared Error: 76.6138\nMean Absolute Error: 6.9780\nRMSE: 8.7529\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"\n\ntest_df = pd.read_csv('/kaggle/input/playground-series-s6e1/test.csv')\ntest_df = OneHot(test_df, cols)\ntest_df[ss] = scaler.fit_transform(test_df[ss])\n\nids = test_df['id']\ntest_df.drop('id',axis = 1, inplace=True)\n\ny_hat_test = gb_model.predict(test_df)\n\nsubmission = pd.DataFrame({\n    \"id\": ids,\n    \"exam_score\": y_hat_test\n})\n\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-13T00:58:19.020182Z","iopub.status.idle":"2026-01-13T00:58:19.020534Z","shell.execute_reply.started":"2026-01-13T00:58:19.020351Z","shell.execute_reply":"2026-01-13T00:58:19.020369Z"}},"outputs":[],"execution_count":null}]}